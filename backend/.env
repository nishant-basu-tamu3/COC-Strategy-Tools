# LLM Provider Configuration
# Options: ollama, gemini
LLM_PROVIDER=gemini

# Ollama configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_LLM_MODEL=mistral:7b

# Gemini configuration
GOOGLE_API_KEY=AIzaSyCzCq8hTf6pcIZtxLw4Qj5oPjdO7Riv8dE
GEMINI_MODEL_NAME=gemini-1.5-flash
GEMINI_EMBEDDING_MODEL=models/embedding-001

# Processing configuration
BATCH_SIZE=16  # Number of documents to process in parallel